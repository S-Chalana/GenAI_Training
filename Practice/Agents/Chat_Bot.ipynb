{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af82d2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-text-splitters in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (1.13.0)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from langchain) (1.0.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from langchain) (2.12.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from langchain-core) (0.4.53)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from langchain-core) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from langchain-core) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.12)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.12.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from langchain-community) (2.0.44)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from langchain-community) (3.13.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=2.1.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from langchain-community) (2.3.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "## Step 1 Install and import dependencies\n",
    "%pip install --upgrade langchain langchain-core langchain-community langchain-text-splitters faiss-cpu pypdf chromadb\n",
    "%pip install gradio --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5be31951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.llms import OpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b03b266e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-6.4.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Downloading pypdf-6.4.0-py3-none-any.whl (329 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-6.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pypdf  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d15e623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8 pages from PDF\n",
      "First page content (first 200 chars):\n",
      "Policy\n",
      "Mandatory\n",
      "September  2012\n",
      "The Nestlé  \n",
      "Human Resources Policy\n"
     ]
    }
   ],
   "source": [
    "## Step 2 Load the Document\n",
    "# Use PyPDFLoader for PDF files\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_path = r\"C:\\Users\\schal\\Documents\\Saruchi\\Gen_AI_Training\\Practice\\Agents\\data\\1728286846_the_nestle_hr_policy_pdf_2012.pdf\"\n",
    "pdf_loader = PyPDFLoader(pdf_path)\n",
    "documents = pdf_loader.load()\n",
    "\n",
    "print(f\"Loaded {len(documents)} pages from PDF\")\n",
    "print(f\"First page content (first 200 chars):\\n{documents[0].page_content[:200]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "967bf137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 document chunks created.\n"
     ]
    }
   ],
   "source": [
    "## Step 3: Split loaded documents into chunks\n",
    "# Use the 'documents' variable from the previous cell\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(documents)\n",
    "print(len(chunks), \"document chunks created.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ddbc3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Generate embeddings \n",
    "MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "hf_embed = HuggingFaceEmbeddings(model_name=MODEL_NAME)\n",
    "\n",
    "# Test embedding on first chunk\n",
    "text = chunks[0].page_content\n",
    "hf_embed_result = hf_embed.embed_documents([text])\n",
    "print(f\"Embedding dimension: {len(hf_embed_result[0])}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e6b5ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for documents (this may take a moment)...\n",
      "Chroma collection 'genai_training_collection' built with 35 documents\n",
      "Chroma collection 'genai_training_collection' built with 35 documents\n"
     ]
    }
   ],
   "source": [
    "## Step 5 Build the ChromaDB vector store (direct chromadb usage)\n",
    "import chromadb\n",
    "# Import embeddings class (ensure available even if import cell wasn't run)\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Provide a lightweight Document class fallback if LangChain schema is not installed\n",
    "try:\n",
    "    # prefer langchain_core if available\n",
    "    from langchain_core.schema import Document\n",
    "except Exception:\n",
    "    try:\n",
    "        from langchain.schema import Document\n",
    "    except Exception:\n",
    "        from dataclasses import dataclass\n",
    "        @dataclass\n",
    "        class Document:\n",
    "            page_content: str\n",
    "            metadata: dict = None\n",
    "\n",
    "# Ensure MODEL_NAME and chunks are defined (from earlier cells)\n",
    "MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "hf_embed = HuggingFaceEmbeddings(model_name=MODEL_NAME)\n",
    "\n",
    "# Create chroma client (avoid deprecated Settings keys)\n",
    "# Use default client constructor which is compatible across Chroma versions.\n",
    "chroma_client = chromadb.Client()\n",
    "collection_name = \"genai_training_collection\"\n",
    "collection = chroma_client.get_or_create_collection(name=collection_name)\n",
    "\n",
    "# Prepare documents and embeddings\n",
    "doc_texts = [c.page_content for c in chunks]\n",
    "ids = [str(i) for i in range(len(doc_texts))]\n",
    "\n",
    "print(\"Computing embeddings for documents (this may take a moment)...\")\n",
    "# Compute embeddings in batches to avoid memory spikes\n",
    "batch_size = 64\n",
    "embeddings_list = []\n",
    "for i in range(0, len(doc_texts), batch_size):\n",
    "    batch = doc_texts[i:i+batch_size]\n",
    "    embeddings_list.extend(hf_embed.embed_documents(batch))\n",
    "\n",
    "# Add to collection (ids, documents, embeddings)\n",
    "# If collection already contains data with same ids, add will error; consider delete+add if re-running\n",
    "try:\n",
    "    collection.add(ids=ids, documents=doc_texts, embeddings=embeddings_list)\n",
    "except Exception as e:\n",
    "    print(\"Warning: collection.add raised:\", e)\n",
    "    # Try upsert if available\n",
    "    try:\n",
    "        collection.upsert(ids=ids, documents=doc_texts, embeddings=embeddings_list)\n",
    "    except Exception:\n",
    "        # as a last resort, clear and add\n",
    "        try:\n",
    "            collection.delete()\n",
    "            collection.add(ids=ids, documents=doc_texts, embeddings=embeddings_list)\n",
    "        except Exception as e2:\n",
    "            print(\"Failed to add documents to Chroma collection:\", e2)\n",
    "\n",
    "# Persist where possible\n",
    "try:\n",
    "    # Newer versions: collection.persist()\n",
    "    collection.persist()\n",
    "except Exception:\n",
    "    try:\n",
    "        chroma_client.persist()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Simple retriever wrapper returning Document objects\n",
    "class ChromaRetriever:\n",
    "    def __init__(self, collection, embedder, k=3):\n",
    "        self.collection = collection\n",
    "        self.embedder = embedder\n",
    "        self.k = k\n",
    "    def get_relevant_documents(self, query):\n",
    "        # compute query embedding\n",
    "        if hasattr(self.embedder, \"embed_query\"):\n",
    "            q_emb = self.embedder.embed_query(query)\n",
    "        else:\n",
    "            q_emb = self.embedder.embed_documents([query])[0]\n",
    "        res = self.collection.query(query_embeddings=[q_emb], n_results=self.k, include=[\"documents\", \"distances\"]) \n",
    "        docs = []\n",
    "        for doc_text in res.get(\"documents\", [[]])[0]:\n",
    "            docs.append(Document(page_content=doc_text))\n",
    "        return docs\n",
    "\n",
    "retriever = ChromaRetriever(collection, hf_embed, k=3)\n",
    "print(f\"Chroma collection '{collection_name}' built with {len(doc_texts)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52219f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured result:\n",
      " {\n",
      "  \"answer\": \"{'answer': 'The Nestle HR policy does not explicitly mention maternity leave.', 'sources': [{'id': 1, 'excerpt': 'This document encompasses the guidelines which constitute a solid basis for effective Human Resources Management throughout the Nestl\\u00e9 Group around the world.'}, {'id': 2, 'excerpt': 'Mandatory'}, {'id': 3, 'excerpt': 'Nestl\\u00e9 not only upholds the freedom of association of its employees and the effective recognition of the right to collective bargaining,'}]}\",\n",
      "  \"sources\": []\n",
      "}\n",
      "\n",
      "Retrieved contexts:\n",
      "\n",
      "[1] The Nestlé Human Resources Policy\n",
      "1\n",
      "At Nestlé, we recognize that our employees \n",
      "are the key to our success and nothing can be \n",
      "achieved without their engagement. \n",
      "This document encompasses the guidelines \n",
      "which constitute a solid basis for effective Human \n",
      "Resources Management throughout the Nestlé \n",
      "Group around the world. It explains to all Nestlé \n",
      "employees the vision and mission of the Human \n",
      "R\n",
      "\n",
      "[2] Policy\n",
      "Mandatory\n",
      "September  2012\n",
      "The Nestlé  \n",
      "Human Resources Policy\n",
      "\n",
      "[3] The Nestlé Human Resources Policy\n",
      "5\n",
      "Since its founding, Nestlé has built a culture \n",
      "based on values of trust, mutual respect and \n",
      "dialogue. Nestlé management and employees all \n",
      "over the world work daily to create and maintain \n",
      "positive individual and collective relationships, \n",
      "and are expected to do so as a core part of their \n",
      "job.\n",
      "Nestlé not only upholds the freedom of \n",
      "association of its employe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Build a question-answering system using the GPT model (citation-aware, structured output)\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from langchain_community.llms import OpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "def _extract_text_from_llm_result(res):\n",
    "    try:\n",
    "        gens = getattr(res, \"generations\", None)\n",
    "        if gens:\n",
    "            first_list = gens[0]\n",
    "            if isinstance(first_list, (list, tuple)) and len(first_list) > 0:\n",
    "                first = first_list[0]\n",
    "                if hasattr(first, \"text\"):\n",
    "                    return first.text\n",
    "                if isinstance(first, dict) and \"text\" in first:\n",
    "                    return first[\"text\"]\n",
    "        if isinstance(res, dict):\n",
    "            choices = res.get(\"choices\")\n",
    "            if choices and len(choices) > 0:\n",
    "                first = choices[0]\n",
    "                if isinstance(first, dict):\n",
    "                    msg = first.get(\"message\") or first.get(\"delta\")\n",
    "                    if isinstance(msg, dict) and \"content\" in msg:\n",
    "                        return msg[\"content\"]\n",
    "                    if \"text\" in first:\n",
    "                        return first[\"text\"]\n",
    "        return str(res)\n",
    "    except Exception:\n",
    "        return str(res)\n",
    "\n",
    "\n",
    "def answer_question_with_context(query, top_k=3, temperature=0.2):\n",
    "    \"\"\"Retrieve top passages, build a citation-aware prompt, call the LLM, and return structured output: {answer: str, sources: [{id:int, excerpt:str}]}\n",
    "\n",
    "    Returns (result_dict, retrieved_texts) where result_dict contains keys \"answer\" and \"sources\".\n",
    "    \"\"\"\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    if not docs:\n",
    "        return {\"answer\": \"No relevant documents found.\", \"sources\": []}, []\n",
    "\n",
    "    # Keep only top_k docs\n",
    "    docs = docs[:top_k]\n",
    "    retrieved_texts = [d.page_content for d in docs]\n",
    "\n",
    "    # Build numbered context with explicit source ids\n",
    "    numbered_passages = [f\"[source {i+1}] {txt}\" for i, txt in enumerate(retrieved_texts)]\n",
    "    context = \"\\n\\n\".join(numbered_passages)\n",
    "\n",
    "    # Ask the model to return JSON with answer and sources array (id + short_excerpt)\n",
    "    prompt_template = ChatPromptTemplate.from_template(\n",
    "        \"You are a precise assistant. Use ONLY the provided context to answer the question.\\n\\n\"\n",
    "        \"Context:\\n{context}\\n\\n\"\n",
    "        \"Question: {question}\\n\\n\"\n",
    "        \"Instructions:\\n\"\n",
    "        \"- Answer concisely (1-3 sentences).\\n\"\n",
    "        \"- If the answer cannot be found in the context, reply exactly: \\\"I don't know.\\\"\\n\"\n",
    "        \"- Provide a JSON object as the ONLY output with keys: 'answer' (string) and 'sources' (array).\\n\"\n",
    "        \"- Each element in 'sources' must be an object with keys 'id' (the source number) and 'excerpt' (a short excerpt <= 200 chars from that source used to support the answer).\\n\"\n",
    "        \"Example output format:\\n{{'answer': '...', 'sources': [{{'id': 1, 'excerpt': '...'}}, ...]}}\\n\\n\"\n",
    "        \"Return only the JSON object (no additional commentary).\"\n",
    "    )\n",
    "\n",
    "    formatted = prompt_template.format(context=context, question=query)\n",
    "\n",
    "    # instantiate LLM\n",
    "    llm = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"), temperature=temperature)\n",
    "\n",
    "    # Try multiple invocation styles\n",
    "    text = None\n",
    "    try:\n",
    "        if hasattr(llm, \"generate\"):\n",
    "            res = llm.generate([formatted])\n",
    "            text = _extract_text_from_llm_result(res)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    if text is None:\n",
    "        try:\n",
    "            if hasattr(llm, \"predict\"):\n",
    "                text = llm.predict(formatted)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    if text is None:\n",
    "        try:\n",
    "            if callable(llm):\n",
    "                text = llm(formatted)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Fallback to OpenAI SDK if nothing yet\n",
    "    if text is None:\n",
    "        try:\n",
    "            from openai import OpenAI as OpenAIClient\n",
    "            client = OpenAIClient(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "            resp = client.chat.completions.create(\n",
    "                model=os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\"),\n",
    "                messages=[{\"role\": \"user\", \"content\": formatted}],\n",
    "                max_tokens=600,\n",
    "            )\n",
    "            text = _extract_text_from_llm_result(resp)\n",
    "        except Exception as e:\n",
    "            return {\"answer\": f\"LLM call failed: {e}\", \"sources\": []}, retrieved_texts\n",
    "\n",
    "    # Try to extract JSON from model output\n",
    "    parsed = None\n",
    "    try:\n",
    "        # 1) direct parse\n",
    "        parsed = json.loads(text)\n",
    "    except Exception:\n",
    "        # 2) try to find JSON substring\n",
    "        m = re.search(r\"\\{[\\s\\S]*\\}\", text)\n",
    "        if m:\n",
    "            try:\n",
    "                parsed = json.loads(m.group(0))\n",
    "            except Exception:\n",
    "                parsed = None\n",
    "\n",
    "    # If parsing failed, attempt to build structured result heuristically\n",
    "    if not isinstance(parsed, dict):\n",
    "        # Heuristic: treat entire text as answer, and list sources = []\n",
    "        result = {\"answer\": text.strip(), \"sources\": []}\n",
    "        return result, retrieved_texts\n",
    "\n",
    "    # Normalize parsed structure\n",
    "    answer = parsed.get(\"answer\") if isinstance(parsed.get(\"answer\"), str) else str(parsed.get(\"answer\", \"\"))\n",
    "    sources_out = []\n",
    "    for s in parsed.get(\"sources\", []):\n",
    "        try:\n",
    "            sid = int(s.get(\"id\")) if isinstance(s, dict) and s.get(\"id\") is not None else None\n",
    "            excerpt = s.get(\"excerpt\") if isinstance(s, dict) else str(s)\n",
    "            if sid is None:\n",
    "                # try to infer id by searching excerpt in retrieved_texts\n",
    "                sid = None\n",
    "                for i, txt in enumerate(retrieved_texts, start=1):\n",
    "                    if excerpt and excerpt.strip()[:40] in txt:\n",
    "                        sid = i\n",
    "                        break\n",
    "            sources_out.append({\"id\": sid, \"excerpt\": excerpt})\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    result = {\"answer\": answer.strip(), \"sources\": sources_out}\n",
    "    return result, retrieved_texts\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    q = \"What does the Nestle HR policy say about maternity leave?\"\n",
    "    res_struct, ctx = answer_question_with_context(q)\n",
    "    print(\"Structured result:\\n\", json.dumps(res_struct, indent=2))\n",
    "    print(\"\\nRetrieved contexts:\\n\")\n",
    "    for i, c in enumerate(ctx, 1):\n",
    "        print(f\"[{i}] {c[:400]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "965c1da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Prompt template to guide the chatbot\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Reusable prompt template for conversational QA that uses retrieved context and cites sources.\n",
    "prompt_template_chatbot = ChatPromptTemplate.from_template(\n",
    "    \"You are a concise, factual assistant. Use ONLY the provided context to answer the user's question.\\n\\n\"\n",
    "    \"Context:\\n{context}\\n\\n\"\n",
    "    \"Question: {question}\\n\\n\"\n",
    "    \"Instructions:\\n\"\n",
    "    \"- Answer concisely (1-3 sentences).\\n\"\n",
    "    \"- Cite supporting sources inline using [source N] markers that correspond to the numbered context entries.\\n\"\n",
    "    \"- If the answer cannot be found in the context, reply exactly: \\\"I don't know.\\\"\\n\"\n",
    "    \"- After the answer, include a short 'Sources:' line listing used source numbers, e.g. 'Sources: [source 1], [source 3]'.\\n\"\n",
    ")\n",
    "\n",
    "# Helper to build numbered context from retrieved texts\n",
    "def build_numbered_context(retrieved_texts: list[str]) -> str:\n",
    "    \"\"\"Return a single string with numbered sources suitable for the prompt template.\"\"\"\n",
    "    return \"\\n\\n\".join([f\"[source {i+1}] {t}\" for i, t in enumerate(retrieved_texts)])\n",
    "\n",
    "# Example (commented) showing how to format the prompt before calling your LLM wrapper:\n",
    "# numbered = build_numbered_context(retrieved_texts)\n",
    "# formatted_prompt = prompt_template_chatbot.format(context=numbered, question=\"Your question here\")\n",
    "# print(formatted_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14638238",
   "metadata": {},
   "outputs": [],
   "source": [
    "## • Step 8: Use Gradio to build a user-friendly chatbot interface, enabling interaction and information retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56bc042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-6.0.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from gradio) (4.11.0)\n",
      "Collecting audioop-lts<1.0 (from gradio)\n",
      "  Downloading audioop_lts-0.2.2-cp313-abi3-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting brotli>=1.1.0 (from gradio)\n",
      "  Downloading brotli-1.2.0-cp313-cp313-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.123.5-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-1.0.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==2.0.1 (from gradio)\n",
      "  Downloading gradio_client-2.0.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from gradio) (0.36.0)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from gradio) (3.0.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from gradio) (2.3.4)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from gradio) (3.11.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from gradio) (25.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from gradio) (2.3.3)\n",
      "Requirement already satisfied: pillow<13.0,>=8.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from gradio) (12.0.0)\n",
      "Requirement already satisfied: pydantic<=2.12.4,>=2.11.10 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from gradio) (2.12.3)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from gradio) (6.0.3)\n",
      "Collecting safehttpx<0.2.0,>=0.1.7 (from gradio)\n",
      "  Downloading safehttpx-0.1.7-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from gradio) (4.15.0)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from gradio-client==2.0.1->gradio) (2025.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Collecting annotated-doc>=0.0.2 (from fastapi<1.0,>=0.115.2->gradio)\n",
      "  Downloading annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
      "Requirement already satisfied: requests in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from pydantic<=2.12.4,>=2.11.10->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from pydantic<=2.12.4,>=2.11.10->gradio) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from pydantic<=2.12.4,>=2.11.10->gradio) (0.4.2)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
      "Downloading gradio-6.0.2-py3-none-any.whl (21.6 MB)\n",
      "   ---------------------------------------- 0.0/21.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.3/21.6 MB 8.9 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 4.2/21.6 MB 11.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 6.8/21.6 MB 11.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 9.7/21.6 MB 12.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 12.6/21.6 MB 12.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 14.9/21.6 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 18.4/21.6 MB 13.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 20.4/21.6 MB 12.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 21.6/21.6 MB 12.0 MB/s  0:00:01\n",
      "Downloading gradio_client-2.0.1-py3-none-any.whl (55 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading audioop_lts-0.2.2-cp313-abi3-win_amd64.whl (30 kB)\n",
      "Downloading fastapi-0.123.5-py3-none-any.whl (111 kB)\n",
      "Downloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Downloading safehttpx-0.1.7-py3-none-any.whl (9.0 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.50.0-py3-none-any.whl (74 kB)\n",
      "Downloading tomlkit-0.13.3-py3-none-any.whl (38 kB)\n",
      "Downloading typer-0.20.0-py3-none-any.whl (47 kB)\n",
      "Downloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
      "Downloading brotli-1.2.0-cp313-cp313-win_amd64.whl (369 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "Downloading ffmpy-1.0.0-py3-none-any.whl (5.6 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub, brotli, tomlkit, shellingham, semantic-version, python-multipart, mdurl, groovy, ffmpy, audioop-lts, annotated-doc, aiofiles, uvicorn, starlette, markdown-it-py, safehttpx, rich, gradio-client, fastapi, typer, gradio\n",
      "\n",
      "   ----------------------------------------  0/21 [pydub]\n",
      "   --- ------------------------------------  2/21 [tomlkit]\n",
      "   ----- ----------------------------------  3/21 [shellingham]\n",
      "   --------- ------------------------------  5/21 [python-multipart]\n",
      "   ----------------- ----------------------  9/21 [audioop-lts]\n",
      "   -------------------- ------------------- 11/21 [aiofiles]\n",
      "   ---------------------- ----------------- 12/21 [uvicorn]\n",
      "   ---------------------- ----------------- 12/21 [uvicorn]\n",
      "   ---------------------- ----------------- 12/21 [uvicorn]\n",
      "   ------------------------ --------------- 13/21 [starlette]\n",
      "   ------------------------ --------------- 13/21 [starlette]\n",
      "   ------------------------ --------------- 13/21 [starlette]\n",
      "   -------------------------- ------------- 14/21 [markdown-it-py]\n",
      "   -------------------------- ------------- 14/21 [markdown-it-py]\n",
      "   -------------------------- ------------- 14/21 [markdown-it-py]\n",
      "   -------------------------- ------------- 14/21 [markdown-it-py]\n",
      "   -------------------------- ------------- 14/21 [markdown-it-py]\n",
      "   ------------------------------ --------- 16/21 [rich]\n",
      "   ------------------------------ --------- 16/21 [rich]\n",
      "   ------------------------------ --------- 16/21 [rich]\n",
      "   ------------------------------ --------- 16/21 [rich]\n",
      "   ------------------------------ --------- 16/21 [rich]\n",
      "   ------------------------------ --------- 16/21 [rich]\n",
      "   -------------------------------- ------- 17/21 [gradio-client]\n",
      "   ---------------------------------- ----- 18/21 [fastapi]\n",
      "   ---------------------------------- ----- 18/21 [fastapi]\n",
      "   ---------------------------------- ----- 18/21 [fastapi]\n",
      "   ---------------------------------- ----- 18/21 [fastapi]\n",
      "   ---------------------------------- ----- 18/21 [fastapi]\n",
      "   ------------------------------------ --- 19/21 [typer]\n",
      "   ------------------------------------ --- 19/21 [typer]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   ---------------------------------------- 21/21 [gradio]\n",
      "\n",
      "Successfully installed aiofiles-24.1.0 annotated-doc-0.0.4 audioop-lts-0.2.2 brotli-1.2.0 fastapi-0.123.5 ffmpy-1.0.0 gradio-6.0.2 gradio-client-2.0.1 groovy-0.1.2 markdown-it-py-4.0.0 mdurl-0.1.2 pydub-0.25.1 python-multipart-0.0.20 rich-14.2.0 safehttpx-0.1.7 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.50.0 tomlkit-0.13.3 typer-0.20.0 uvicorn-0.38.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "## Install Gradio\n",
    "%pip install gradio --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f568a96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Gradio chatbot interface for RAG system — return structured JSON result\n",
    "import gradio as gr\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "def run_query(question: str):\n",
    "    \"\"\"Run the QA pipeline and return the structured JSON result and retrieved contexts.\"\"\"\n",
    "    if not question or not question.strip():\n",
    "        return json.dumps({\"error\": \"Please enter a question.\"}, indent=2), \"\"\n",
    "    try:\n",
    "        res_struct, contexts = answer_question_with_context(question)\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"Error running QA pipeline: {e}\"}, indent=2), \"\"\n",
    "\n",
    "    # Ensure res_struct is serializable dict\n",
    "    try:\n",
    "        result_json = json.dumps(res_struct, indent=2, ensure_ascii=False)\n",
    "    except Exception:\n",
    "        # Fallback: convert to string inside JSON\n",
    "        result_json = json.dumps({\"answer\": str(res_struct)}, indent=2, ensure_ascii=False)\n",
    "\n",
    "    # Short preview of retrieved contexts\n",
    "    contexts_text = \"\\n\\n\".join([f\"[{i+1}] {c[:600]}\" for i, c in enumerate(contexts)]) if contexts else \"\"\n",
    "\n",
    "    return result_json, contexts_text\n",
    "\n",
    "\n",
    "def launch_gradio():\n",
    "    iface = gr.Interface(\n",
    "        fn=run_query,\n",
    "        inputs=gr.Textbox(lines=2, placeholder=\"Ask a question about the uploaded documents...\", label=\"Question\"),\n",
    "        outputs=[\n",
    "            gr.Textbox(label=\"Result (JSON)\"),\n",
    "            gr.Textbox(label=\"Retrieved Contexts (truncated)\")\n",
    "        ],\n",
    "        title=\"Nestlé Chatbot\",\n",
    "        description=\"Ask questions about the documents indexed in the Chroma collection. Returns structured JSON result and retrieved contexts.\",\n",
    "    )\n",
    "    iface.launch()\n",
    "\n",
    "# Launch when run as a cell (uncomment to start the UI):\n",
    "launch_gradio()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
