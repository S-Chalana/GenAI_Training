{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b849b91",
   "metadata": {},
   "source": [
    "%pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13a7b6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Downloading ollama-0.6.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from ollama) (2.12.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from httpx>=0.27->ollama) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from httpx>=0.27->ollama) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from httpx>=0.27->ollama) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from pydantic>=2.9->ollama) (2.41.4)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from pydantic>=2.9->ollama) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from pydantic>=2.9->ollama) (0.4.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\schal\\documents\\saruchi\\gen_ai_training\\.venv\\lib\\site-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n",
      "Downloading ollama-0.6.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: ollama\n",
      "Successfully installed ollama-0.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38b774d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "def ask_question_local_llm(prompt):\n",
    "    print(f\"user asked {prompt}\")\n",
    "    response = ollama.chat(\n",
    "        model=\"llama3\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI assitant - Respond in one line\"},\n",
    "            {\"role\": \"user\", \"content\": prompt} \n",
    "        ]\n",
    "    )\n",
    "    return response['message']['content']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9968b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user asked What is the capital of France?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = ask_question_local_llm(\"What is the capital of France?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fae4d65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------------------------Local LLM Response------------------------- \n",
      "user asked what is the best ollama model for windows\n",
      "Time taken by Local LLM: 33.05658578872681 seconds\n",
      "\n",
      "Local LLM says: The best Ollama model for Windows is the Ollama V4.0, which offers advanced features such as real-time object detection, improved tracking capabilities, and compatibility with a wide range of Windows versions.\n",
      "\n",
      "\n",
      "-------------------------Local LLM Response------------------------- \n",
      "user asked what is ollama good for\n",
      "Time taken by Local LLM: 34.03151750564575 seconds\n",
      "\n",
      "Local LLM says: Ollama is a free online meeting and collaboration tool that allows users to host virtual meetings, share screens, and collaborate on projects with up to 12 participants simultaneously, making it an excellent choice for remote teams, students, and freelancers.\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "while True:\n",
    "    user_prompt = input(\"Ask me anything\")\n",
    "    if (user_prompt.lower() != 'quit'):\n",
    "        print(\"\\n\\n-------------------------Local LLM Response------------------------- \")\n",
    "        start = time.time()\n",
    "        response_local= ask_question_local_llm(user_prompt)\n",
    "        end = time.time()\n",
    "        print(f\"Time taken by Local LLM: {end - start} seconds\")\n",
    "        print(\"\\nLocal LLM says:\", response_local)  \n",
    "\n",
    "        time.sleep(3)\n",
    "\n",
    "    else:\n",
    "       print(\"Exiting...\")\n",
    "       break    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd2f6f9",
   "metadata": {},
   "source": [
    "## Local LLM vs OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bf65c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "def ask_question_local_llm(prompt):\n",
    "    print(f\"user asked {prompt}\")\n",
    "    response = ollama.chat(\n",
    "        model=\"llama3\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI assitant - Respond in one line\"},\n",
    "            {\"role\": \"user\", \"content\": prompt} \n",
    "        ]\n",
    "    )\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db6ec922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv(override=True, dotenv_path=\".env\")\n",
    "my_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print (my_api_key)\n",
    "my_client = OpenAI(api_key=my_api_key)\n",
    "\n",
    "\n",
    "import base64\n",
    "\n",
    "image_path1 = \"data/invoice.png\" \n",
    "image_path2 = \"data/office_lease.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0118f456",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m     image_base64 = base64.b64encode(f.read()).decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m     mime_type = \u001b[33m\"\u001b[39m\u001b[33mimage/png\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     response = \u001b[43mclient\u001b[49m.chat.completions.create(\n\u001b[32m      7\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mgpt-5-nano\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     messages=[\n\u001b[32m      9\u001b[39m         {\n\u001b[32m     10\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mYou extract and summarize information from invoices or forms.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m         },\n\u001b[32m     13\u001b[39m         {\n\u001b[32m     14\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     16\u001b[39m                 {\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mExtract as many fields, such as Invoice from/Company, Invoice, Invoice information - number, data, due date etc, Invoice product list from this image as a JSON object:\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m     17\u001b[39m                 {\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mimage_url\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mimage_url\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33murl\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdata:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmime_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage1_base64\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m}}\n\u001b[32m     18\u001b[39m             ]\n\u001b[32m     19\u001b[39m         }\n\u001b[32m     20\u001b[39m     ],\n\u001b[32m     21\u001b[39m )\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mðŸ§¾ Extracted Info from Image:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.choices[\u001b[32m0\u001b[39m].message.content)\n",
      "\u001b[31mNameError\u001b[39m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "with open(image_path1, \"rb\") as f:\n",
    "    image_base64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "    mime_type = \"image/png\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You extract and summarize information from invoices or forms.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Extract as many fields, such as Invoice from/Company, Invoice, Invoice information - number, data, due date etc, Invoice product list from this image as a JSON object:\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:{mime_type};base64,{image1_base64}\"}}\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"ðŸ§¾ Extracted Info from Image:\\n\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34b69ac3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m mime_type = \u001b[33m\"\u001b[39m\u001b[33mimage/png\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Request extraction from image\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m response = \u001b[43mclient\u001b[49m.chat.completions.create(\n\u001b[32m      8\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mgpt-5-nano\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     messages=[\n\u001b[32m     10\u001b[39m         {\n\u001b[32m     11\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mExtract and summarize information from this property for sale flyer.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     13\u001b[39m         },\n\u001b[32m     14\u001b[39m         {\n\u001b[32m     15\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     16\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     17\u001b[39m                 {\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mExtract key fields from this image, such as property title, details etc as a JSON object:\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m     18\u001b[39m                 {\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mimage_url\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mimage_url\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33murl\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdata:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmime_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage2_base64\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m}}\n\u001b[32m     19\u001b[39m             ]\n\u001b[32m     20\u001b[39m         }\n\u001b[32m     21\u001b[39m     ],\n\u001b[32m     22\u001b[39m )\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mðŸ§¾ Extracted Info from Image:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.choices[\u001b[32m0\u001b[39m].message.content)\n",
      "\u001b[31mNameError\u001b[39m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "with open(image_path2, \"rb\") as f:\n",
    "    image2_base64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "mime_type = \"image/png\"\n",
    "\n",
    "# Request extraction from image\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Extract and summarize information from this property for sale flyer.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Extract key fields from this image, such as property title, details etc as a JSON object:\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:{mime_type};base64,{image2_base64}\"}}\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"ðŸ§¾ Extracted Info from Image:\\n\")\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
